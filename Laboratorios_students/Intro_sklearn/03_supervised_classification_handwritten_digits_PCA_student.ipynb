{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage supervisé: Classification de chiffres ecrits à la main\n",
    "\n",
    "In this section we'll apply scikit-learn to the classification of handwritten\n",
    "digits.  This will go a bit beyond the iris classification we saw before: we'll\n",
    "discuss some of the metrics which can be used in evaluating the effectiveness\n",
    "of a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapté du cours de Gaël Varoquaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll re-use some of our code from before to visualize the data and remind us what\n",
    "we're looking at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))  # figure size in inches\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the digits: each image is 8x8 pixels\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(digits.images[i], cmap=plt.cm.binary, interpolation='nearest')\n",
    "    \n",
    "    # label the image with the target value\n",
    "    ax.text(0, 7, str(digits.target[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de visualiser des données \n",
    "\n",
    "A good first-step for many problems is to visualize the data using a\n",
    "*Dimensionality Reduction* technique.  We'll start with the\n",
    "most straightforward one, Principal Component Analysis (PCA).\n",
    "\n",
    "PCA seeks orthogonal linear combinations of the features which show the greatest\n",
    "variance, and as such, can help give you a good idea of the structure of the\n",
    "data set.  You can use `PCA` or use `RandomizedPCA`, because it's faster for large `N`.\n",
    "\n",
    "Creer la projection `proj` des variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2, svd_solver=\"randomized\")\n",
    "proj = pca.fit_transform(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire un plot avec `plt.scatter(X1, X2, c=y)` et `plt.colorbar();` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(proj[:, 0], proj[:, 1], c=digits.target)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: Given these projections of the data, which numbers do you think\n",
    "a classifier might have trouble distinguishing?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a\n",
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets\n",
    "\n",
    "# train the model\n",
    "\n",
    "# use the model to predict the labels of the test data\n",
    "predicted = #TODO\n",
    "expected = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: why did we split the data into training and validation sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the digits again with the predicted labels to get an idea of\n",
    "how well the classification is working:\n",
    "\n",
    "On affiche en vert quand la prediciton est bonne et en rouge quand elle est mauvaise (utiliser la variable `predicted`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 6))  # figure size in inches\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the digits: each image is 8x8 pixels\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(X_test.reshape(-1, 8, 8)[i], cmap=plt.cm.binary,\n",
    "              interpolation='nearest')\n",
    "    \n",
    "    # label the image with the target value\n",
    "    if predicted[i] == expected[i]:\n",
    "        ax.text(0, 7, str(predicted[i]), color='green')\n",
    "    else:\n",
    "        ax.text(0, 7, str(predicted[i]), color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Measurement of Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to measure the performance of our estimator without having to resort\n",
    "to plotting examples.  A simple method might be to simply compare the number of\n",
    "matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = (predicted == expected)\n",
    "print(matches.sum())\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.sum() / float(len(matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maintenant plus de métriques : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that nearly 1500 of the 1800 predictions match the input.  But there are other\n",
    "more sophisticated metrics that can be used to judge the performance of a classifier:\n",
    "several are available in the ``sklearn.metrics`` submodule.\n",
    "\n",
    "One of the most useful metrics is the ``classification_report``, which combines several\n",
    "measures and prints a table with the results:\n",
    "\n",
    "Utiliser `pandas.DataFrame` pour visualiser de manière simple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from pandas import DataFrame\n",
    "DataFrame(metrics.classification_report(expected, predicted, output_dict=True)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrice de confusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another enlightening metric for this sort of multi-label classification\n",
    "is a *confusion matrix*: it helps us visualize which labels are\n",
    "being interchanged in the classification errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que vois-t-on de particulier par rapport aux erreur de notre modèle ? Est-ce normal ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tester sur l'ensemble d'entrainement \n",
    "\n",
    "Regardons si le modele est meilleur sur l'ensemble qu'il a utilisé pour s'entrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison avec un autre modele : le Bayesien Naïf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
